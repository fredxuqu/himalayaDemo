第一章：互联网金融业申请评分卡

信用违约风险的基本概念
	交易对手未能履行约定契约中的义务而造成经济损失的风险，即授信人不能履行还本付息的责任
	而使授信人的预期收益与实际收益发生偏离的可能性，他是金融风险的主要类型。
	
	组成部分
		PD  Probability of Default 	违约概率
		LGD Loss Given Default		违约条件下的损失率
		EAD Exposure at Default		违约风险下的敞口暴露
		RWA Risk Widget Assert		风险权重资产
		EL	Expect Loss				期望损失
		
	信用违约的主体
	个人违约：个人向金融机构借贷后，没有在规定的期限之内还款的行为。
	公司违约：公司向金融机构借贷后，没有在规定的期限之内还款的行为，或者公司在发行债券后，
		没有履行或者延期履行利息或者本金的支付义务。
	主权违约：一国政府无法按时对其向外担保借来的债务还本付息的情况。
	
	个贷中常用的违约定义
		M3 & M3+ 逾期
		债务重组
		个人破产
		银行主动关户或注销
		其他相关违法行为
	M0 M1 M2 的定义
	M0：最后缴款日的第二天到下一个账单日
	M1:	M0时段的延续，在未还款的第二个账单日到第二次账单的最后缴款日之间
	M2：M1的延续，即在未还款的第三个账单日到第三次账单日的最后缴款日。
	
申请评分卡的重要性和特性
	什么是评分卡？
	信贷场景中的评分卡
		以分数的形式来衡量风险几率的一种手段
		是对未来一段时间内违约/逾期/失联概率的预测
		有一个明确的正区间
		通常分数越高越安全
		数据驱动
		反欺诈评分卡，申请评分卡，行为评分卡，催收评分卡
	
	在申请环节，以申请者在申请当日及过去的信息为基础，预测未来放款后的预期
	或者违约概率。
	评分卡作用：
		风险控制
		营销
		资本管理
		
	特性：
		稳定性：数据不变，分数也不应该变
		区分性：违约人群与正常人群的分数应当有显著差异
		预测能力：低分人群的违约率更高
		和预期概率等价：评分可以精准的反映违约/预期概率，反之亦然
	
	评估放款过程:
		用户申请
		准入规则
		反欺诈
		三方核验
		申请评分通过
		放款
	
	模型开发步骤:
		立项：场景、对象、目的
		数据准备与预处理：账户、客群、内部/外部数据
		模型构建：区分度、预测性、稳定性
		验证/审计：是否计算错误、逻辑错误、业务错误
		模型部署：从开发环境到生产环境、容量、并发度
		模型监控：性能是否减弱，是否需要优化或者重新开发
		
	常用模型：
		逻辑回归：简单、稳定、可解释、技术成熟、易于检测和部署
			 但是准确度不高
		决策树：对数据质量要求低，已解释
			准确度不高
		其他元模型
		组合模型：准确度高，不易过拟合
			 不易解释、部署困难、计算量大
				  
	申请评分卡常用的特征：
		个人信息：学历，性别，收入	（还款能力）
		负债信息：在经融机构的负债信息	(还款意愿)
		消费能力：商品购买记录，处境游，奢侈品消费	(还款意愿)
		历史信用记录：历史逾期行为		（还款能力）
		新兴数据：人际社交，网络足迹，出行，个人财务
		评分等级 = 意愿 * 能力
		
	数据来自于 Lending Club
	
	数据与描述
		申请额度
		产品期限
		利率
		工作年限
		住宅
		收入
		收入核验
		收款目的
		联系方式
		两年内的逾期次数
		6个月的咨询次数
		上次逾期距今的月数
		征信局中记录的信用产品
		公众不良记录数
		贷款状态
		
非平衡样本问题的定义和解决方法
	在分类问题中，每种类别的出现概率未必均衡
		信用风险：正常用户远多于逾期/违约的用户
		流失风险：留存的客户多于流失的客户
		
	非平衡样本的隐患：
		降低对少类样本的灵敏性
	
	非平衡样本的解决方案：
		过采样：
			优点：简单，对数据质量要求不高
			缺点：过拟合
		欠采样：
			有点：简单，对数据质量要求不高
			缺点：丢失重要信息
		SMOTE:
			人工合成算法 Synthetic Minority Oversampling Technique
			不易过拟合，保留信息
			不能对有缺失值和类别变量做处理
		SMOTE算法
		采用最邻近算法，计算每个少数类样本的K个近邻
		从K个近邻中随机挑选N个样本进行随机线性插值
		构造新的少数样本数
			new = Xi + rand(0,1) * (Yj - Xi) 			j = 1,2,...,N
		将新样本与原数据合成，产生新的训练集
			
申请评分卡中的数据预处理和特征衍生
	构建信用风险类型的特征
		数据预处理
			数据预处理
				时间格式
				缺失值
				极值
				
				数据格式的处理（数据格式必须统一，且能被程序顺利识别）
					利率
					日期
					工作年限
					文本类数据的处理方式
						主题提取（nlp）
							提取准确，详细的信息，对风险的评估非常有效
							但是NLP的模型较为复杂，且需要足够多的训练样本
						编码
				缺失值
					缺失在数据分析的工作是频繁出现的。
					缺失的种类：
						完全随机缺失
						随机缺失
						完全非随机缺失
					处理方法
						补缺
						作为一种状态
						
			特征构造
				计数
				比例
				距离
				
				常用的特征衍生：通过人工经验衍生，或者通过模型自动衍生 Auto Encoder
				计数：过去一年内申请贷款的总次数
				求和：过去一年内的网店消费总额
				比例：贷款申请额度与年收入的占比
				时间差：第一次开户距今时长
				波动率：过去三年内每份工作的时间的标准差
				
			特征选择
				相关性
				差异性
				显著性
			模型参数估计
				回归系数
				模型复杂度
					
	特征的分箱
		为什么要分箱？
			使箱内的数据特征差异尽可能的小，箱与箱之间的差异尽可能明显
		分箱的定义
			将连续变量离散化
			将多状态的离散变量合并成少状态
		分箱的重要性
			稳定性：避免特征中无意义的波动对评分带来的波动
			健壮性：避免了极端值的影响
		
		特征的分箱
			优势：可以将缺失作为独立的一个箱带入模型中，将所有的变量换到相似的尺度上
			限制：计算量大，分箱后需要编码
		
		分箱的方法：
			有监督的
				Best-KS
				算法原理：让分箱后组别的分布的差异最大化
				对于连续变量：
					1. 排序 x={x1,x2,....xk}
					2. 计算每一个点的KS值
					3. 选取最大的KS对应的特征值Xm，将x分成{xi<=xm} 与 {xi>xm} 两部分
					对于每一部分，重复2-3步，直到满足终止条件之一
				终止条件：
					下一步分箱后，最小的箱的占比低于设定的阈值
					下一步分箱后，有一箱对应的Y类别全部为0或者1
					下一步分箱后，bad rate 不单调
						bad rate 坏样本率
				对于离散度很高的变量
					编码
					依据连续变量的方式进行分箱
					
				ChiMerge(卡方分箱)
				通俗的来讲卡方分箱法：自底向上，将连续性的变量离散化的一种分箱方法，它是依赖于卡方检验，
				卡方分箱法首先将样本数据分成若干个分组，然后将两两相邻的两个组合并，使得合并完之后，卡方值最小
					假设，样本中工资的分布为1000-10000，
				1. 将样本排序，并等分为10组，
					0-1000,
					1001-2000，
					2001-3000，
					3001-4000，
					4001-5000，
					5001-6000，
					6001-7000，
					7001-8000，
					8001-9000，
					9001-10000
				2. 使用两两相邻的两组，计算一个卡方值，这样会计算出来9个卡方值
				3. 将计算出来的卡方值最小的两组合并
				重复2-3部，直到满足卡方分箱的终止条件
				
				自底向上的（即基于合并的）数据离散化方法。他依赖于卡方检验，具有最小卡
				方值的相邻区间合并在一起，知道满足确定的停止准则。
				基本思想：对于精确的离散化，相对类频率在一个区间内应当完全一致，因此，
				如果两个相邻的区间具有非常类似的类分布，则这两个区间可以合并，否则，它
				们应当保持分开。而低卡方值表明它们具有相似的类分布。
				和Best-KS相比，ChiMerge可以应用在multi-class的情况下。
				具体算法：
					1. 预先设定一个卡方的阈值
					2. 初始化，根据要离散的属性对实例进行排序，每个实例属于一个区间
					3. 合并区间
						计算每一对相邻区间的卡方值
						将卡方值最小的一对区间合并
					
						X*X = SUM(SUM((Aij - Eij) * (Aij - Eij) / Eij))  i={1,2} j={1,2}  
						Aij : 第i区间第j类的实例的数量
						Eij ：Aij的期望频率， = Ni * Cj / N , N是总样本数，Nj是第i组的样本数，
							Cj是第j类样本在全体中的比例
				卡方阈值的确定
					根据显著性水平和自由度得到卡方值
					自由度比类别数量小1，例如有三类，自由度为2，则90%置信度（10%显著性水平）下，
					卡方的值为4.6
				阈值的意义
					类别和属性独立是，有90%的可能性，计算得到的卡方值会小于4.6，这样，大于阈值
					的卡方值就说明属性和类不是相互独立的，不能合并。如果阈值选的打，区间合并就
					会进行很多次，离散后的区间数量少，区间打。
				算法推荐使用0.90,0.95,0.99置信度，最大区间数取10-15之间。
				也可以不用卡方阈值，此时可以考虑最小区间数或者最大区间数，指定区间数量的上限和下限
				最多几个区间，最少几个区间。
				对于类别型变量，需要分箱时需要按照某种方式进行排序。
				
				分箱注意：
					默认分成五个箱
					检查分箱后的bad rate单调性，倘若不满足，需要进行相邻两箱的合并，知道bad rate为止
					上述过程是收敛的，因为当箱数为2时，bad rate自然单调
					分箱必须覆盖所有的训练样本外不可能存在的值
					原始值很多时，为了减小时间的开销，通常选取较少（例如50个）初始切分点。但是要注意分布不均匀
					避免等距划分，而采用等频划分
					
					对于类别型变量
						当类别数较少时，原则上不需要分箱
						当某个或者某几个类别的badrate为0时，需要和最小的非0的 bad rate 的箱进行合并
						当该变量可以完全区分目标变量时，需要认真检查该变量的合理性。
															
			无监督
				等频
					区间的边界值要经过选择，使得每个区间包含大致相等的实例数量，
					比如说：N=10，每个区间应该包含大约10%的实例
				等距
					从最小值到最大值之间，均分为N等份，这样如果AB为最小最大值，则每个区间的长度为
					W = (B-A)/N
					区间边界值为 A + W， A + 2W，.... A+(N-1)W
				聚类
				
				等频和等距的算法的弊端
					等距的，会导致低于或者高于自大最小区间边界值的都归于最低区间或者最高区间
					等频的也是一样
					例如：工资分箱
					都分为5个箱
					等距的区间划分会导致最高工资为50000，导致所有的工资低于10000的人都被划分到同一区间
					等频的则相反，导致所有工资高于50000的人都被划分到50000这一区间。
				这个栗子有点问题？
	
	WOE编码
		weight of evidence
		一种有监督的编码方式，将预测类别的集中度的属性作为编码的数值
		优势：
			将特征的值规范到相近的尺度上，基于经验，WOE的绝对值波动范围在 0.1 - 3 之间
			具有业务含义
		缺点：
			需要每个箱中同时包含好、坏两个类别
	
		计算公式
					good		bad			Good Percent		Bad Percent
		G1			g1			b1			g1/Gtotal			b1/Btotal
		G2			g2			b2			g2/Gtotal			b2/Btotal
		...			...			...			...					...
		GN			g3			b3			g3/Gtotal			b3/Btotal
		Total		Gtotal		Btotal
	
		把全体样本按照某一个属性分箱之后，统计每个箱中的好坏样本数量，然后统计全体样本中的好坏样本
		然后统计出每箱中好样本与全体样本中好样本的比 RGi，某箱重坏样本与全体坏样本的占比RBi
		然后求出 log(RGi/RBi)
		WOEi = log((Gi/Gtotal)/(Bi/Btotal))
		
		1. 每箱中的数据必须包含好坏样本 Gi 与 Bi 都要大于 0，如果分子或分母不能为零
		2. WOE 有可能为正，负 或 0
		3. 好样本或者坏样本都可以作为分子或者分母，但是在整个评分卡模型中必须保持一致性
				
		WOE编码的意义
			符号与好样本比例相关
			要求回归模型的系数为负
		
		https://github.com/andysda/python_scorecard
						
第三讲：
	申请评分卡中的数据预处理和特征衍生
	特征信息度的计算和意义
		变量挑选
		在评分卡模型中，变量挑选是非常重要的工作
		变量间的共线性，线性相关性
			信息冗余
			降低了显著性，甚至造成符号失真。
		加剧了后期验证、部署、监控的负担
		业务上含义不充分
	
	变量挑选的依据
		带约束：LASSO
		特征重要性：随机森林
		模型拟合优质和复杂度：基于AIC的逐步回归
		变量信息度：IV
		
	IV是如何计算的呢？
		首先计算出WOE值，IV是在WOE的基础之上加权，得出每箱的IV是多少
		IV是基于变量的，WOE是基于分箱的
		箱号		好样本数	坏样本数	好样本率%(1)		坏样本率%(2)		WOE(log(1/2))		IV((1-2)*WOE)
		Group1	G1		B1		G1/G			B1/B			log((G1/G)/(B1/B))	(G1/G-B1/B)*log((G1/G)/(B1/B))
		Group2	G2		B2		G2/G			B2/B			log((G2/G)/(B2/B))	(G2/G-B2/B)*log((G2/G)/(B2/B))
		Group3	G3		B3		G3/G			B3/B			log((G3/G)/(B3/B))	(G3/G-B3/B)*log((G3/G)/(B3/B))
		Group4	G4		B4		G4/G			B4/B			log((G4/G)/(B4/B))	(G4/G-B4/B)*log((G4/G)/(B4/B))
		....
		GroupN	GN		BN		GN/G			BN/B			log((GN/G)/(BN/B))	(GN/G-BN/B)*log((GN/G)/(BN/B))
		
		Total	G=∑Gi	B=∑Bi														∑(Gi/G-Bi/B)*log((Gi/G)/(Bi/B))
		
		IVi = (Gi-Bi) * log(Gi/Bi) = (Gi-Bi) * WOEi
		其中Gi Bi代表箱i中好坏样本占全体好坏样本的比例
		WOE: 衡量两类样本分布的差异性
		Gi-Bi : 衡量差异的重要性
			例如： G1=0.2 ， B1=0.1  与 G2=0.02， B2=0.01
			WOE1 = WOE2 = log(2)
			IV1 = (0.2-0.1)*log(2) = 0.1 * log(2)
			IV2 = (0.2-0.1)*log(2) = 0.1 * log(2)
			
	特征信息的作用：
		挑选变量
			非负指标
			高IV表示该特征和目标变量的关联度高
			目标变量只能是二分类
			过高的IV，可能有潜在的风险（小于1.2）
			特征分箱越细，IV越高，这就是为什么分箱数一般定位5
			业界常用的阈值
				小于0.02: 	没有预测性，不可用
			  	0.02-0.1 	弱预测性
			  	0.1-0.2		有一定预测性
			  	大于0.2		高预测性
	
	单变量分析和多变量分析：
	单变量分析：依据变量的某些属性，从初选名单中筛选出合适的变量进入缩减名单（shortlist）
		需要分析的变量属性
		变量的显著性
		变量的分布
		变量的业务含义
	以分箱之后的WOE为值
		用IV检验有效性
		连续变量bad rate的单调性（可以放宽到U型）
		单一区间的占比不宜过高		
	
	IV分布
	
	多变量分析：变量的两两相关性
		当相关性高时，只能保留一个
		可以选择IV高的
		可以选择分箱均衡的
			先得对IV进行排序，然后两两结合再确定那个变量放入模型中。
		
		多重共线性：
			两两变量拿出来，其线性相关性是比较低的，但是把所有的放一起之后，相关性就比较高了。
			
			通常用VIF来衡量，要求VIF<10
				VIFi = 1/(1-Ri*Ri)
			Ri 是变量{X1,X2,X3,X4....XN},对Xi的线性回归R平方
			
	WOE相关性矩阵
		
				
第四讲：逻辑回归
	专家模型
	数理统计模型：逻辑回归模型
	机器学习模型
	
	逻辑回归的概念：
		伯努利分布
		从概率的角度来说，逾期是一种随机事件，如何刻画它的随机性？
		伯努利分布:一种离散分布，用于表示0-1型事件发生的概率
		P（逾期）=p， P（不逾期）= 1-p
		合并起来，可以是：
			P（Y=y）= (p^y)(1-p)^(1-y)
				y = 1: 逾期
				  = 0: 不逾期
			求导数后
				p(概率）= 逾期（不逾期）总数 / 总的样本数
		
		不同的申请人，逾期概率不同，即
			p = f(x1,x2,x3,....,xk) 
				其中{x1,x2,x3,....xk}是申请人的个人资质
			p的特点
				有界
				不可直接观察
			可以用线性回归吗？
	
	变量挑选
		作用和目的
			剔除掉跟目标变量不太相关的特征
			消除多重共线性的影响
			增加解释性
		变量挑选和降维
			变量挑选
			主成分分析：降维，但是没有剔除变量
		常用手段
			LASSO
			逐步回归法
				向前挑选
				向后挑选
				双向挑选
				向前向后法的结合
			随机森林法
				过拟合
				
第五讲：评分卡模型的评价标准
	评分卡最终的目的：尽可能的将人群分成好，较好，坏人群。
	模型的区分度
		评分卡模型的结果需要能对好、坏人群给出一定的区分度。
		衡量的方法：
		1. 好坏人群的分数的分布的差异
			KS（Kolmogorov-Smirnov）
			KS = max{ Bad.k / Bad.total - Good.k / Good.total }
			KS高，说明了样本的区域分布大，表示模型的区分度好
			KS > 0.3
		2. 好、坏人群的分数的距离
			Divergence
			用于两个评分卡模型，在同样一批样本上模型好坏，可以采用Divergence区别
		3. 好、坏人群浓度的差异
			Gini
				
	准确度：
		混淆矩阵
						真实
						坏					好
			预测 	坏	True Positive(TP)	False Positive(FP)
				好	False Negative(FN)	False Negative（TN）
		
			真正类率：TPR (true positive rate)
				代表分类器预测的正类中，实际正实例所占所有正实例的比例（Sensitivity）
				TP/(TP + FN) ：  预测成坏样本个数/所有的真正的样本里面面
				
			负正类率：FPR (false positive rate)
				代表分类器预测的正类中，实际负实例所占所有负实例的比例（Sensitivity）
				TP/(TP + FN) ：  预测成坏的个数/所有真正的好样本
				
			真负类率： TNR (true negative rate)
				代表分类器预测的负类中，实际负实例所占所有负实例的比例（Specificity）
				TNR = 1 - FPR
					
						
		ROC曲线	
		
			
第六讲：行为评分卡模型
	基本概念
		根据贷款人放贷后的表现行为，预测未来预期/违约风险概率的模型
	使用场景：
		与申请评分卡不同，行为评分卡用在贷款发放之后，到期之前的时间段，即贷中环节
	使用目的
		监控贷款人在贷款结束之前的逾期/违约风险
	额度管理（循环）	
	
	还款率
	过去一段时间的还款率
	
	额度使用率		
	过去一段时间的平均额度使用率
	
	DPD: day past to
			
			
			
			
			
			