1. Install
	http://www.apache.org/dyn/closer.cgi/lucene/solr/6.2.1
	download from https://mirrors.tuna.tsinghua.edu.cn/apache/lucene/solr/6.2.1/
	
	unzip 
	https://mirrors.tuna.tsinghua.edu.cn/apache/lucene/solr/6.2.1/solr-6.2.1.tgz

2. Config dataSource for DIH
	<dataConfig>
	    <dataSource class="com.alibaba.druid.pool.DruidDataSource" 
					driver="oracle.jdbc.driver.OracleDriver" 
					url="jdbc:oracle:thin:@localhost:1521:orcl" 
					user="scott" 
					password="sa" 
					name="druidDS"/>
					
		<dataSource name="jndiDataSource" jndiName="java:comp/env/jdbc/jndiDS" type="JdbcDataSource"/>
		
	    <document>
	        <entity dataSource="druidDS" name="tagEntity" pk="ID" 
					query="select id,tag_name,type,status,rank,modify_time from tb_social_statistics "
					deltaImportQuery="select id,tag_name,type,status,rank,modify_time from tb_social_statistics where id = ${dih.delta.ID}"
					deltaQuery="select id from tb_social_statistics where modify_time > to_date('${dataimporter.last_index_time}','yyyy-mm-dd HH24:SS:MI')" >
	                
	            <field column="ID" name="id" />
				<field column="TAG_NAME" name="tagName" />
				<field column="TYPE" name="type" />
				<field column="STATUS" name="status" />
				<field column="RANK" name="rank" />
				<field column="MODIFY_TIME" name="modifyTime" />            
	        </entity>
	    </document>
	</dataConfig>	

	NOTE: column name should be uppercase. 
	
3. schema.xml configuration.
	type:
	<fieldType name="string" class="solr.StrField" sortMissingLast="true" />
	<fieldType name="int" class="solr.TrieIntField" precisionStep="0" positionIncrementGap="0"/>
	<fieldType name="random" class="solr.RandomSortField" indexed="true" />
	<fieldType name="text_ws" class="solr.TextField" positionIncrementGap="100">
      <analyzer>
        <tokenizer class="solr.WhitespaceTokenizerFactory"/>
      </analyzer>
    </fieldType>
    <fieldType name="text_general" class="solr.TextField" positionIncrementGap="100">
      <analyzer type="index">
        <tokenizer class="solr.StandardTokenizerFactory"/>
        <filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords.txt" />
        <!-- in this example, we will only use synonyms at query time
        <filter class="solr.SynonymFilterFactory" synonyms="index_synonyms.txt" ignoreCase="true" expand="false"/>
        -->
        <filter class="solr.LowerCaseFilterFactory"/>
      </analyzer>
      <analyzer type="query">
        <tokenizer class="solr.StandardTokenizerFactory"/>
        <filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords.txt" />
        <filter class="solr.SynonymFilterFactory" synonyms="synonyms.txt" ignoreCase="true" expand="true"/>
        <filter class="solr.LowerCaseFilterFactory"/>
      </analyzer>
    </fieldType>
    
    descriptions:
	    name: identity
	    class： 
	    sortMissingLast
	    sortMissingFirst
	    anlyzer
	    type
	    tokenizer
	    filter
	    
	b.	fields: 
		field: fixed fields
		dynamicField:
		copyField 
			multiValued=true
			name
			class
			indexed
			stored: if field is not indexed, it must be stored
			omitNorms
			termVectors
			compressed
			multiValued
			positionIncrementGap
	d.	uniqueKey
	e.	defaultSearchField
	f.	solrQueryParser: and/or
			

4. solrconfig.xml
	solr performance factors
		useCompoundFile
		ramBufferSizeMB
		maxBufferedDocs
		mergeFactor
		maxIndexingThreads: Max number of IndexWriter tasks.
		lockType: single, native, JVM, simple
		unlockOnStartup
	
	query
		maxBooleanClauses
		filterCache: filter cache
		queryResultCache: cache searching result, a list of document ids;
		documentCache: 
		fieldValueCache: field cache, quick search by document id, will be created by default.
		enableLazyFieldLoading
		queryResultWindowSize
		queryResultMaxDocsCached
		listener
		useColdSearcher
		maxWarmingSearchers
		
		
		
	BooleanQuery
	

3. config JNDI
	a. 	copy jetty-jndi-9.3.8.v20160314.jar and jetty-plus-9.3.8.v20160314.jar to solr_home/server/lib
	b.	change druid source code and override setPassword method, then copy druid.jar and oracle driver to solr_home/server/lib/ext
	c.	add below config to solr_home/server/contexts/solr-jetty-context.xml
		<New id="pysearch" class="org.eclipse.jetty.plus.jndi.Resource">
			<Arg></Arg>
			<Arg>jdbc/jndiDS</Arg>
			<Arg>
				<New class="com.alibaba.druid.pool.DruidDataSource">
					<Set name="driverClassName">oracle.jdbc.driver.OracleDriver</Set>  
					<Set name="url">jdbc:oracle:thin:@localhost:1521:orcl</Set>  
					<Set name="username">scott</Set>
					<Set name="password">{MD5}9fdd42c2a7390d3</Set>
				</New>
			</Arg>  
		</New>
	Note: sometimes, you must only use jndiDS to reference the JNDI data source.
		
	d.	add below config to solr-6.3.0\server\solr-webapp\webapp\WEB-INF\web.xml
		<resource-ref>
			<description>Text JNDI Reference</description>
			<res-ref-name>textjndi</res-ref-name>
			<res-type>java.lang.String</res-type>
			<res-auth>Container</res-auth>
		</resource-ref>

4. Config smartcn
	
4. Config IK analysis
	config ik analyser for solr (never succ)
		download related ikanalyser config
		copy ik-analyzer-solr-6.3.0.jar to \solr-6.3.0\server\solr-webapp\webapp\WEB-INF\lib
		
		copy IKAnalyzer.cfg.xml、mydict.dic、stopword.dic to 
		/usr/local/solr-6.3.0/server/solr-webapp/webapp/WEB-INF/classes
		
	add below config to managed-schema
	<fieldType name="text_ik" class="solr.TextField" >
		<analyzer type="index" >
			<tokenizer class="org.wltea.analyzer.lucene.IKTokenizerFactory" useSmart="false" conf="ik.conf"/>
			<filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords.txt" />
		</analyzer>
		<analyzer type="query">
			<tokenizer class="org.wltea.analyzer.lucene.IKTokenizerFactory" useSmart="false" conf="ik.conf"/>
			<filter class="solr.StopFilterFactory" ignoreCase="true" words="stopwords.txt" />
		</analyzer>
	</fieldType>
	
	<field name="text_ik"  type="text_ik" indexed="true"  stored="true"  multiValued="true" />
	
	
		
4. solr6.3.0 + tomcat8 
	blog:	http://blog.csdn.net/yzl_8877/article/details/53199355
	a.  download and unzip solr
	b.	copy solr-6.3.0\server\solr-webapp\webapp to tomcat_home\webapps, then change name to solr
	c.	create solr_home under solr-6.3.0\server\solr-webapp\webapp to tomcat_home\webapps\solr
	d.	copy all files under solr-6.3.0\server\solr to solr_home
	e.	copy all jars under solr-6.3.0\server\lib\ext to webapps\solr\WEB-INF\lib
	f.	copy solr-6.3.0\server\resources\log4j.properties to webapps\solr\WEB-INF\classes
	g.	modify webapps\solr\WEB-INF\web.xml and open <evn-entry>, change as below
		<env-entry>
	       <env-entry-name>solr/home</env-entry-name>
	       <env-entry-value>E:\solr\apache-tomcat-8\webapps\solr\solr_home</env-entry-value>
	       <env-entry-type>java.lang.String</env-entry-type>
	    </env-entry>
	h. 	modify tomcat\conf\server.xml
		<Context path="solr" docBase="E:\solr\apache-tomcat-8\webapps\solr" sessionCookieName="ksessionid"/>

	i.	remove <auth-constraint /> from webapps\solr\WEB-INF\web.xml
	j.	http://127.0.0.1:8080/solr/index.html

	set SOLR TIME ZONE
	set SOLR_TIMEZONE=UTC/GMT+08:00
	
	-Dfile.encoding=UTF-8
	

5. How to import csv file
	1. add CSVHandler to solrconfig.xml
	<requestHandler name="/update/csv" class="solr.CSVRequestHandler" startup="lazy">
		<lst name="defaults">
	   		<str name="separator">;</str>
	   		<str name="header">true</str>
	   		<str name="skip">publish_date</str>
	   		<str name="encapsulator">"</str>
		</lst>
  	</requestHandler>
		
	2. add config to schema-manage
		<field name="id" type="string" indexed="true" stored="true" required="true" multiValued="false" />
   		<field name="newscontent" type="text_general" indexed="true" stored="true" />
		
	3. prepare csv file 
		id,newscontent
		1,"Hello World"
		2,"solr 世界美好"
		3,"软件开发,java技术"
	
	4. execute command to import
		http://localhost:8983/solr/news/update?stream.file=E:/solr/solr-6.3.0/example/exampledocs/news.csv&stream.contentType=text/csv;charset=utf-8&fieldnames=id,newscontent&overwrite=false&commit=true

6. solr searching grammar
	1. indexing
		SolrInputDocument doc = new SolrInputDocument();
		doc.setField("id","abc");
		doc.setField("content","hi jack");
		server.add(doc);
		server.commit;
		
		server.deleteById(id);
		server.deleteById(ids);
		server.deleteByQuery("*:*");
		
		SolrQuery query = new SolrQuery();
		query.set("q","*.*");
		QueryResponse rsp =server.query(query)
		SolrDocumentList list = rsp.getResults();
		for (int i = 0; i < list.size(); i++) {
			SolrDocument sd = list.get(i);
			String id = (String) sd.getFieldValue("id");
			System.out.println(id);
		}
		
	2. optimize solr index
		q:	查询字符串，必须的。
		fq:	filter query。使用Filter Query可以充分利用Filter Query Cache，提高检索性能。作用：在q查询符合结果中同时是fq查询符合的，例如：q=mm&fq=date_time:[20081001 TO 20091031]，找关键字mm，并且date_time是20081001到20091031之间的。
		fl:	field list。指定返回结果字段。以空格“ ”或逗号“,”分隔。
		start:	用于分页定义结果起始记录数，默认为0。
		rows 用于分页定义结果每页返回记录数，默认为10。
		sort 排序，格式:sort=<field name>+<desc|asc>[,<field name>+<desc|asc>]… 。示例：（inStock desc, price asc）表示先 “inStock” 降序, 再 “price” 升序，默认是相关性降序。
		df 默认的查询字段，一般默认指定。
		q.op 覆盖schema.xml的defaultOperator（有空格时用"AND"还是用"OR"操作逻辑），一般默认指定。必须大写
		wt writer type。指定查询输出结构格式，默认为“xml”。在solrconfig.xml中定义了查询输出格式：xml、json、python、ruby、php、phps、custom。
		qt query type，指定查询使用的Query Handler，默认为“standard”。
		explainOther 设置当debugQuery=true时，显示其他的查询说明。
		defType
		设置查询解析器名称。
		timeAllowed
		设置查询超时时间。
		omitHeader
		设置是否忽略查询结果返回头信息，默认为“false”。
		indent
		返回的结果是否缩进，默认关闭，用 indent=true|on 开启，一
		般调试json,php,phps,ruby输出才有必要用这个参数。
		version
		查询语法的版本，建议不使用它，由服务器指定默认值。
		debugQuery
		设置返回结果是否显示Debug信息。
		
		
	1. keep search order
		localhost:8983/solr/news/select/q=newscontent="南华"~8&fl=id,newscontent&sort=score desc&fq=status:2&start=0&rows=10&defType=complexphrase&wt=json&indent=true
		
		http://localhost:8983/solr/news/select?q=newscontent:"上海"~8&fl=id,newscontent&sort=score desc&start=0&rows=10&defType=complexphrase&wt=json&indent=true
	
7. configure and use spatial search
	
	
